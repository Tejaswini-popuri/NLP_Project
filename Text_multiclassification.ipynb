{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c30fc2",
   "metadata": {},
   "source": [
    "# Reddit Submission Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a78480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5742f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('C:/Users/Tejaswini/Documents/MSIS_COURSE/Coursework/Summer_2022/Self_Practice/redditnlp_0na.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c6fd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wopny7</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 15 Au...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>50</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 15 Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wqp4qm</td>\n",
       "      <td>When you are invited to a ‘town hall’ amidst a...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>When you are invited to a ‘town hall’ amidst a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrd1s7</td>\n",
       "      <td>Resume critique (trying to get an internship o...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Resume critique (trying to get an internship o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrc8ad</td>\n",
       "      <td>Advice - Looking for a Data Scientist</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Been trying to find a solid Data Scientist for...</td>\n",
       "      <td>51</td>\n",
       "      <td>Advice - Looking for a Data Scientist Been try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wriszy</td>\n",
       "      <td>Recommendations for Udemy class on deploying a...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>I use Python mostly. Trying to move from analy...</td>\n",
       "      <td>0</td>\n",
       "      <td>Recommendations for Udemy class on deploying a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title    subreddit  \\\n",
       "0  wopny7  Weekly Entering & Transitioning - Thread 15 Au...  datascience   \n",
       "1  wqp4qm  When you are invited to a ‘town hall’ amidst a...  datascience   \n",
       "2  wrd1s7  Resume critique (trying to get an internship o...  datascience   \n",
       "3  wrc8ad              Advice - Looking for a Data Scientist  datascience   \n",
       "4  wriszy  Recommendations for Udemy class on deploying a...  datascience   \n",
       "\n",
       "                                                body  num_comments  \\\n",
       "0   \\n\\nWelcome to this week's entering & transit...            50   \n",
       "1                                                NaN            85   \n",
       "2                                                NaN            13   \n",
       "3  Been trying to find a solid Data Scientist for...            51   \n",
       "4  I use Python mostly. Trying to move from analy...             0   \n",
       "\n",
       "                                            all_text  \n",
       "0  Weekly Entering & Transitioning - Thread 15 Au...  \n",
       "1  When you are invited to a ‘town hall’ amidst a...  \n",
       "2  Resume critique (trying to get an internship o...  \n",
       "3  Advice - Looking for a Data Scientist Been try...  \n",
       "4  Recommendations for Udemy class on deploying a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfb65f",
   "metadata": {},
   "source": [
    "### Finding if any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef4a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              False\n",
       "title           False\n",
       "subreddit       False\n",
       "body             True\n",
       "num_comments    False\n",
       "all_text        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2cb03",
   "metadata": {},
   "source": [
    "##### Body seems to be having missing values. Using fillna() to fill it with empty space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324e9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.body.fillna(' ',axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42a982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['all_text'] = posts['title'] + ' '+posts['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3432c703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wopny7</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 15 Au...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>50</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 15 Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wqp4qm</td>\n",
       "      <td>When you are invited to a ‘town hall’ amidst a...</td>\n",
       "      <td>datascience</td>\n",
       "      <td></td>\n",
       "      <td>85</td>\n",
       "      <td>When you are invited to a ‘town hall’ amidst a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrd1s7</td>\n",
       "      <td>Resume critique (trying to get an internship o...</td>\n",
       "      <td>datascience</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>Resume critique (trying to get an internship o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrc8ad</td>\n",
       "      <td>Advice - Looking for a Data Scientist</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Been trying to find a solid Data Scientist for...</td>\n",
       "      <td>51</td>\n",
       "      <td>Advice - Looking for a Data Scientist Been try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wriszy</td>\n",
       "      <td>Recommendations for Udemy class on deploying a...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>I use Python mostly. Trying to move from analy...</td>\n",
       "      <td>0</td>\n",
       "      <td>Recommendations for Udemy class on deploying a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title    subreddit  \\\n",
       "0  wopny7  Weekly Entering & Transitioning - Thread 15 Au...  datascience   \n",
       "1  wqp4qm  When you are invited to a ‘town hall’ amidst a...  datascience   \n",
       "2  wrd1s7  Resume critique (trying to get an internship o...  datascience   \n",
       "3  wrc8ad              Advice - Looking for a Data Scientist  datascience   \n",
       "4  wriszy  Recommendations for Udemy class on deploying a...  datascience   \n",
       "\n",
       "                                                body  num_comments  \\\n",
       "0   \\n\\nWelcome to this week's entering & transit...            50   \n",
       "1                                                               85   \n",
       "2                                                               13   \n",
       "3  Been trying to find a solid Data Scientist for...            51   \n",
       "4  I use Python mostly. Trying to move from analy...             0   \n",
       "\n",
       "                                            all_text  \n",
       "0  Weekly Entering & Transitioning - Thread 15 Au...  \n",
       "1  When you are invited to a ‘town hall’ amidst a...  \n",
       "2  Resume critique (trying to get an internship o...  \n",
       "3  Advice - Looking for a Data Scientist Been try...  \n",
       "4  Recommendations for Udemy class on deploying a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4868661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "title           0\n",
       "subreddit       0\n",
       "body            0\n",
       "num_comments    0\n",
       "all_text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2886d3b",
   "metadata": {},
   "source": [
    "#### Dropping the columns title and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.drop(columns=['title','body'],axis=0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cef3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5729, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0c5f6",
   "metadata": {},
   "source": [
    "#### Shuffling the records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405c2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = posts.sample(frac=1).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0c23f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w8nqot</td>\n",
       "      <td>artificial</td>\n",
       "      <td>1</td>\n",
       "      <td>How NASA AI Robot Assists Astronauts On Intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vjlhee</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>4</td>\n",
       "      <td>[D] Publishing two papers at the same time Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgmu9c</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>4</td>\n",
       "      <td>[P] Colab Themes: A Chrome Extension to Custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iorbjg</td>\n",
       "      <td>datascience</td>\n",
       "      <td>86</td>\n",
       "      <td>Experience/Advice from a 10+ year data scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wei6yb</td>\n",
       "      <td>datascience</td>\n",
       "      <td>0</td>\n",
       "      <td>Looking for: ESG / Impact / Sustainability dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        subreddit  num_comments  \\\n",
       "0  w8nqot       artificial             1   \n",
       "1  vjlhee  MachineLearning             4   \n",
       "2  vgmu9c  MachineLearning             4   \n",
       "3  iorbjg      datascience            86   \n",
       "4  wei6yb      datascience             0   \n",
       "\n",
       "                                            all_text  \n",
       "0  How NASA AI Robot Assists Astronauts On Intern...  \n",
       "1  [D] Publishing two papers at the same time Let...  \n",
       "2  [P] Colab Themes: A Chrome Extension to Custom...  \n",
       "3  Experience/Advice from a 10+ year data scienti...  \n",
       "4  Looking for: ESG / Impact / Sustainability dat...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05566c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5729 entries, 0 to 5728\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            5729 non-null   object\n",
      " 1   subreddit     5729 non-null   object\n",
      " 2   num_comments  5729 non-null   int64 \n",
      " 3   all_text      5729 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 179.2+ KB\n"
     ]
    }
   ],
   "source": [
    "shuffled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fe32f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "subreddit       0\n",
       "num_comments    0\n",
       "all_text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd4024",
   "metadata": {},
   "source": [
    "shuffled.dropna(axis = 0,how = 'any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6b8c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5729, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60035d",
   "metadata": {},
   "source": [
    "#### Removing links from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b302de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2f41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(corpus):\n",
    "    new_corpus = []\n",
    "    for i in corpus:\n",
    "        new_corpus.append(re.sub(r'http\\S+', '', i))\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "565ed96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled['all_text_1']= pd.Series(remove_links(shuffled.all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "320929c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_text</th>\n",
       "      <th>all_text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>cbnftu</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>84</td>\n",
       "      <td>[News] DeepMind’s StarCraft II Agent AlphaStar...</td>\n",
       "      <td>[News] DeepMind’s StarCraft II Agent AlphaStar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>q9hhqt</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>61</td>\n",
       "      <td>[P] YoHa: A practical hand tracking engine.</td>\n",
       "      <td>[P] YoHa: A practical hand tracking engine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>skc72q</td>\n",
       "      <td>datascience</td>\n",
       "      <td>137</td>\n",
       "      <td>What's a sign somebody's unusually good at SQL...</td>\n",
       "      <td>What's a sign somebody's unusually good at SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>nino7x</td>\n",
       "      <td>datascience</td>\n",
       "      <td>88</td>\n",
       "      <td>Need to go back to the basics, what's your fav...</td>\n",
       "      <td>Need to go back to the basics, what's your fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>w59y4o</td>\n",
       "      <td>datascience</td>\n",
       "      <td>5</td>\n",
       "      <td>Missing observations at household level but ha...</td>\n",
       "      <td>Missing observations at household level but ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        subreddit  num_comments  \\\n",
       "2824  cbnftu  MachineLearning            84   \n",
       "2286  q9hhqt  MachineLearning            61   \n",
       "2466  skc72q      datascience           137   \n",
       "2020  nino7x      datascience            88   \n",
       "2660  w59y4o      datascience             5   \n",
       "\n",
       "                                               all_text  \\\n",
       "2824  [News] DeepMind’s StarCraft II Agent AlphaStar...   \n",
       "2286      [P] YoHa: A practical hand tracking engine.     \n",
       "2466  What's a sign somebody's unusually good at SQL...   \n",
       "2020  Need to go back to the basics, what's your fav...   \n",
       "2660  Missing observations at household level but ha...   \n",
       "\n",
       "                                             all_text_1  \n",
       "2824  [News] DeepMind’s StarCraft II Agent AlphaStar...  \n",
       "2286      [P] YoHa: A practical hand tracking engine.    \n",
       "2466  What's a sign somebody's unusually good at SQL...  \n",
       "2020  Need to go back to the basics, what's your fav...  \n",
       "2660  Missing observations at household level but ha...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8dcb9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "subreddit       0\n",
       "num_comments    0\n",
       "all_text        0\n",
       "all_text_1      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce7fdc",
   "metadata": {},
   "source": [
    "### Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "770fcdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tejaswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tejaswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = list(tokenize(text))\n",
    "    #res = ' '.join([stemmer.stem(t.lower()) for t in tokens if t.lower() not in stop_words]) \n",
    "    res = ' '.join([lemmatizer.lemmatize(t.lower()) for t in tokens if t.lower() not in stop_words]) \n",
    "    if len(res) == 0:\n",
    "        return ' '\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25800a45",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97d58ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(shuffled.all_text_1,shuffled.subreddit, random_state=3, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a28bfed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfa73651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1719,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3547c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db79629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1719,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10923c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3536    [P] Cosplayer Faces generate by Nvidia StyleGA...\n",
       "2733    [D] Train-Valid-Test split and featurizer desi...\n",
       "4218    Data Analyst Research Oppurtunity for High Sch...\n",
       "5284    This Tumblr user had a neural net generate and...\n",
       "4585    In the next five years, computer programs that...\n",
       "                              ...                        \n",
       "789     [R] The Annotated Diffusion Model From hugging...\n",
       "968     Poisson reg Hi, I am currently trying to test ...\n",
       "1667    It's crazy how effective it's to include \"Data...\n",
       "3321    [D] Have you ever been asked to work on a soft...\n",
       "1688    [Project] I've compiled weather/climate date f...\n",
       "Name: all_text_1, Length: 4010, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c1818fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3536    MachineLearning\n",
       "2733    MachineLearning\n",
       "4218        datascience\n",
       "5284         artificial\n",
       "4585         artificial\n",
       "             ...       \n",
       "789     MachineLearning\n",
       "968         datascience\n",
       "1667        datascience\n",
       "3321    MachineLearning\n",
       "1688    MachineLearning\n",
       "Name: subreddit, Length: 4010, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c58c58",
   "metadata": {},
   "source": [
    "## Make Document-Term Matrices(Using CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676452b3",
   "metadata": {},
   "source": [
    "### Build Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fd05a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(preprocessor=<function clean_text at 0x000002BD15144790>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "count_vect = CountVectorizer(preprocessor=clean_text, ngram_range=(1,1)) \n",
    "count_vect.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2668b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_by',\n",
       " '_causal',\n",
       " '_check',\n",
       " '_clip_gradients',\n",
       " '_cpu',\n",
       " '_creator',\n",
       " '_cv',\n",
       " '_data',\n",
       " '_debug',\n",
       " '_detection',\n",
       " '_diffusion',\n",
       " '_dims',\n",
       " '_dir',\n",
       " '_e',\n",
       " '_estimators']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()[10:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4689b3c",
   "metadata": {},
   "source": [
    "### Build Document-Term matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70386366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mat = count_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56c66c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010, 15809)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a13c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mat = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc5d2f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1719, 15809)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceb8fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8993e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32caf62",
   "metadata": {},
   "source": [
    "### Train with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c59b58eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cl = MultinomialNB()\n",
    "cl.fit(X_train_mat,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c64dd",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56ceba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MachineLearning', 'artificial', 'MachineLearning', ...,\n",
       "       'MachineLearning', 'artificial', 'MachineLearning'], dtype='<U15')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cl.predict(X_test_mat)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea24afb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 3.22157517e-301, 0.00000000e+000],\n",
       "       [7.82914997e-002, 9.19756338e-001, 1.95216271e-003],\n",
       "       [5.38977772e-001, 4.40373152e-001, 2.06490763e-002],\n",
       "       ...,\n",
       "       [9.99962472e-001, 2.02778121e-007, 3.73251068e-005],\n",
       "       [1.22384514e-001, 8.41808988e-001, 3.58064978e-002],\n",
       "       [8.48862566e-001, 1.29770957e-001, 2.13664765e-002]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.predict_proba(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "934dd5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejaswini\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ind = np.abs(cl.coef_[0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a017710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8815,  7847,  9958, ...,  5195, 11505,  4325], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58a0bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7c60983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ed'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()[ind[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e652cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db99ba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: model\n",
      "1: learning\n",
      "2: paper\n",
      "3: data\n",
      "4: like\n",
      "5: ai\n",
      "6: machine\n",
      "7: one\n",
      "8: research\n",
      "9: time\n",
      "10: ml\n",
      "11: using\n",
      "12: use\n",
      "13: work\n",
      "14: would\n",
      "15: training\n",
      "16: image\n",
      "17: network\n",
      "18: also\n",
      "19: deep\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    index = ind[i]\n",
    "    print(f'{i}: {features[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaaf019",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ee1de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.72      0.80      0.75       598\n",
      "     artificial       0.83      0.66      0.73       561\n",
      "    datascience       0.80      0.88      0.84       560\n",
      "\n",
      "       accuracy                           0.78      1719\n",
      "      macro avg       0.78      0.78      0.78      1719\n",
      "   weighted avg       0.78      0.78      0.78      1719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee732d20",
   "metadata": {},
   "source": [
    "#### Classification report for ngrams ranging from 1 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa69f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_mat for 1 ngram/ngrams: (4010, 15809)\n",
      "Shape of X_test_mat for 1  ngram/ngrams: (1719, 15809)\n",
      "Shape of y_train for 1  ngram/ngrams: (4010,)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "y_pred values: ['MachineLearning', 'artificial', 'MachineLearning', 'artificial', 'MachineLearning', 'artificial', 'MachineLearning', 'datascience', 'datascience', 'datascience']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "prediction probability: [[1.00000000e+000 3.22157517e-301 0.00000000e+000]\n",
      " [7.82914997e-002 9.19756338e-001 1.95216271e-003]\n",
      " [5.38977772e-001 4.40373152e-001 2.06490763e-002]\n",
      " [2.19783802e-002 9.77884104e-001 1.37516159e-004]\n",
      " [5.86144876e-001 4.08324160e-001 5.53096345e-003]\n",
      " [5.80538566e-002 9.38445722e-001 3.50042164e-003]\n",
      " [5.47286020e-001 3.71310571e-001 8.14034088e-002]\n",
      " [1.97471505e-005 3.77696883e-007 9.99979875e-001]\n",
      " [3.07210236e-002 9.03008522e-008 9.69278886e-001]\n",
      " [3.10147878e-002 5.60464861e-003 9.63380564e-001]]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Classification Report for 1 ngram/ngrams: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.72      0.80      0.75       598\n",
      "     artificial       0.83      0.66      0.73       561\n",
      "    datascience       0.80      0.88      0.84       560\n",
      "\n",
      "       accuracy                           0.78      1719\n",
      "      macro avg       0.78      0.78      0.78      1719\n",
      "   weighted avg       0.78      0.78      0.78      1719\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of X_train_mat for 2 ngram/ngrams: (4010, 183578)\n",
      "Shape of X_test_mat for 2  ngram/ngrams: (1719, 183578)\n",
      "Shape of y_train for 2  ngram/ngrams: (4010,)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "y_pred values: ['MachineLearning', 'MachineLearning', 'MachineLearning', 'artificial', 'MachineLearning', 'artificial', 'datascience', 'datascience', 'datascience', 'datascience']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "prediction probability: [[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.22052215e-01 3.63880960e-01 1.40668253e-02]\n",
      " [8.30568080e-01 3.88737215e-02 1.30558199e-01]\n",
      " [9.94674558e-02 9.00473366e-01 5.91780492e-05]\n",
      " [9.75188139e-01 1.68502543e-02 7.96160654e-03]\n",
      " [5.17220053e-02 9.47533154e-01 7.44840603e-04]\n",
      " [3.03515722e-01 1.36861919e-05 6.96470592e-01]\n",
      " [3.83338004e-08 8.73879817e-13 9.99999962e-01]\n",
      " [1.59760904e-04 1.28430816e-22 9.99840239e-01]\n",
      " [4.80542420e-04 9.51773286e-06 9.99509940e-01]]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Classification Report for 2 ngram/ngrams: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.63      0.87      0.73       598\n",
      "     artificial       0.90      0.41      0.57       561\n",
      "    datascience       0.79      0.89      0.84       560\n",
      "\n",
      "       accuracy                           0.73      1719\n",
      "      macro avg       0.77      0.72      0.71      1719\n",
      "   weighted avg       0.77      0.73      0.71      1719\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of X_train_mat for 3 ngram/ngrams: (4010, 395150)\n",
      "Shape of X_test_mat for 3  ngram/ngrams: (1719, 395150)\n",
      "Shape of y_train for 3  ngram/ngrams: (4010,)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "y_pred values: ['MachineLearning', 'MachineLearning', 'MachineLearning', 'artificial', 'MachineLearning', 'artificial', 'datascience', 'datascience', 'datascience', 'datascience']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "prediction probability: [[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.98462159e-01 1.84125960e-01 1.74118814e-02]\n",
      " [8.50742684e-01 1.56766268e-02 1.33580689e-01]\n",
      " [2.56249150e-01 7.43605017e-01 1.45833728e-04]\n",
      " [9.86502028e-01 5.54536993e-03 7.95260216e-03]\n",
      " [2.05369069e-02 9.79171067e-01 2.92026320e-04]\n",
      " [3.27928992e-01 8.16858328e-07 6.72070191e-01]\n",
      " [4.07266193e-08 1.96771344e-13 9.99999959e-01]\n",
      " [2.00721169e-04 7.63255478e-26 9.99799279e-01]\n",
      " [1.20733053e-04 1.91342141e-06 9.99877354e-01]]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Classification Report for 3 ngram/ngrams: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.61      0.87      0.72       598\n",
      "     artificial       0.91      0.36      0.52       561\n",
      "    datascience       0.79      0.90      0.84       560\n",
      "\n",
      "       accuracy                           0.71      1719\n",
      "      macro avg       0.77      0.71      0.69      1719\n",
      "   weighted avg       0.77      0.71      0.69      1719\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Shape of X_train_mat for 4 ngram/ngrams: (4010, 609553)\n",
      "Shape of X_test_mat for 4  ngram/ngrams: (1719, 609553)\n",
      "Shape of y_train for 4  ngram/ngrams: (4010,)\n",
      "------------------------------------------------------------------------------------------------------\n",
      "y_pred values: ['MachineLearning', 'MachineLearning', 'MachineLearning', 'artificial', 'MachineLearning', 'artificial', 'datascience', 'datascience', 'datascience', 'datascience']\n",
      "------------------------------------------------------------------------------------------------------\n",
      "prediction probability: [[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.43470313e-01 1.38402935e-01 1.81267519e-02]\n",
      " [8.57857126e-01 1.00420515e-02 1.32100822e-01]\n",
      " [3.43047176e-01 6.56761046e-01 1.91778126e-04]\n",
      " [9.88196538e-01 3.95267112e-03 7.85079124e-03]\n",
      " [2.86201170e-02 9.70978816e-01 4.01067244e-04]\n",
      " [3.38017709e-01 2.92099115e-07 6.61981999e-01]\n",
      " [4.17298653e-08 1.14346224e-13 9.99999958e-01]\n",
      " [2.28532031e-04 4.22063423e-27 9.99771468e-01]\n",
      " [1.22111845e-04 1.48524536e-06 9.99876403e-01]]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Classification Report for 4 ngram/ngrams: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.60      0.88      0.71       598\n",
      "     artificial       0.91      0.33      0.48       561\n",
      "    datascience       0.78      0.90      0.84       560\n",
      "\n",
      "       accuracy                           0.70      1719\n",
      "      macro avg       0.76      0.70      0.68      1719\n",
      "   weighted avg       0.76      0.70      0.68      1719\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "for i in range(1,5):\n",
    "    count_vect = CountVectorizer(preprocessor=clean_text, ngram_range=(1,i)) \n",
    "    count_vect.fit(X_train) \n",
    "    #Build Document -term matrices\n",
    "    X_train_mat = count_vect.transform(X_train)\n",
    "    print(f'Shape of X_train_mat for {i} ngram/ngrams: '+ str(X_train_mat.shape))\n",
    "    X_test_mat = count_vect.transform(X_test)\n",
    "    print(f'Shape of X_test_mat for {i}  ngram/ngrams: '+ str(X_test_mat.shape))\n",
    "    print(f'Shape of y_train for {i}  ngram/ngrams: '+ str(y_train.shape))\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    cl = MultinomialNB()\n",
    "    cl.fit(X_train_mat,y_train)\n",
    "    y_pred = cl.predict(X_test_mat)\n",
    "    print(f'y_pred values: '+ str(list(y_pred)[:10]))\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print(f'prediction probability: '+ str(cl.predict_proba(X_test_mat)[:10]))\n",
    "    print('------------------------------------------------------------------------------------------------------')\n",
    "    print(f'Classification Report for {i} ngram/ngrams: \\n'+classification_report(y_test,y_pred))\n",
    "    print('------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9bcdc",
   "metadata": {},
   "source": [
    "The unigrams had better precision and F1 score than any other n gram range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3337b2",
   "metadata": {},
   "source": [
    "## Make Document-Term Matrix (Using TFIDF vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e253588",
   "metadata": {},
   "source": [
    "To analyze the prediction for the words that are not common among the 3 classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d904b",
   "metadata": {},
   "source": [
    "### Build Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe1d0126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(preprocessor=<function clean_text at 0x000002BD15144790>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(preprocessor= clean_text,ngram_range=(1,1))\n",
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5143d",
   "metadata": {},
   "source": [
    "### Build Document-Term Matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "892e8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mat1 = tfidf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef1f9cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010, 15809)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fcb9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mat1 = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da188cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1719, 15809)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mat1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82343b",
   "metadata": {},
   "source": [
    "### Train with Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dff71e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e75ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.fit(X_train_mat1,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e8c5f",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "860b5bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MachineLearning', 'artificial', 'MachineLearning', ...,\n",
       "       'MachineLearning', 'artificial', 'MachineLearning'], dtype='<U15')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = cl.predict(X_test_mat1)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43b77580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89067176, 0.02341545, 0.08591279],\n",
       "       [0.29615529, 0.49097407, 0.21287064],\n",
       "       [0.43729809, 0.33734631, 0.2253556 ],\n",
       "       ...,\n",
       "       [0.62900399, 0.07409674, 0.29689927],\n",
       "       [0.26651137, 0.48454461, 0.24894402],\n",
       "       [0.51993187, 0.31824092, 0.1618272 ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.predict_proba(X_test_mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d677a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.abs(cl.coef_[0]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7a8408a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8815,  7847,  9958, ..., 10583,  3748, 11168], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2af2fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b261fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: quotation\n",
      "1: diagnose\n",
      "2: practises\n",
      "3: pragmatic\n",
      "4: dgp\n",
      "5: pramukh\n",
      "6: praying\n",
      "7: prebuilt\n",
      "8: dfs\n",
      "9: dfphd\n",
      "10: df_no_nulls_norm\n",
      "11: precleaned\n",
      "12: preconceived\n",
      "13: predefine\n",
      "14: df_no_nulls\n",
      "15: predetermined\n",
      "16: df_metrics\n",
      "17: df\n",
      "18: predicted_df\n",
      "19: predicted_variable_name\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    index = ind[-1-i]\n",
    "    print(f'{i}: {features[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7188ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: model\n",
      "1: learning\n",
      "2: paper\n",
      "3: machine\n",
      "4: image\n",
      "5: deep\n",
      "6: ml\n",
      "7: network\n",
      "8: research\n",
      "9: neural\n",
      "10: using\n",
      "11: data\n",
      "12: ai\n",
      "13: training\n",
      "14: like\n",
      "15: video\n",
      "16: code\n",
      "17: one\n",
      "18: would\n",
      "19: time\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    index = ind[i]\n",
    "    print(f'{i}: {features[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe48dc1",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b837b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "MachineLearning       0.69      0.79      0.74       598\n",
      "     artificial       0.89      0.55      0.68       561\n",
      "    datascience       0.74      0.90      0.81       560\n",
      "\n",
      "       accuracy                           0.75      1719\n",
      "      macro avg       0.77      0.75      0.74      1719\n",
      "   weighted avg       0.77      0.75      0.74      1719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
